{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### HA\n",
    "### A general script/function/wrapper that takes in: \n",
    "### * genetic data in a matrix A containing N SNPs (these are the rows), and k ancestries (these are the first k columns);\n",
    "###   the final column of A is total allele frequecy; therefore, A is size N x (k+1)\n",
    "### * a starting guess\n",
    "### and returns:\n",
    "### * the hidden proportions of every ancestry in the data.\n",
    "\n",
    "import numpy as np\n",
    "import scipy as scipy\n",
    "from scipy.optimize import minimize\n",
    "import timeit\n",
    "\n",
    "def HA(A,x_guess):\n",
    "    \n",
    "    # Grab the value of k\n",
    "    k=np.shape(A)[1] - 1        # Note that we substract by 1 since the last column of A is total allele frequncy data\n",
    "    \n",
    "    # Grab and define the total allele frequency\n",
    "    taf=A[:,k:(k+1)]\n",
    "    \n",
    "    # This is the objective function!\n",
    "\n",
    "    def obj_fun(x):\n",
    "        b=0\n",
    "        for i in range(0,k):\n",
    "            b=b + x[i]*A[:,i:(i+1)]\n",
    "        b=b-taf\n",
    "        return np.sum(b**2, axis=0)[0]\n",
    "    \n",
    "    # Here is the gradient of the objective function\n",
    "\n",
    "    def grad_obj_fun(x):\n",
    "\n",
    "        gradvec = np.zeros((k,1))\n",
    "\n",
    "        d=0\n",
    "\n",
    "        for i in range(0,k):\n",
    "            d=d + x[i]*A[:,i:(i+1)]\n",
    "        d=d-taf\n",
    "\n",
    "        for i in range(0,k):\n",
    "            gradvec[i,:] = np.sum(2*A[:,i:(i+1)]*d, axis=0)\n",
    "        return gradvec\n",
    "\n",
    "    # These are wrappers that make our constraints and our bounds\n",
    "\n",
    "    cons = ({'type': 'eq', 'fun': lambda x:  np.sum(x,axis=0) -1},)\n",
    "\n",
    "    for i in range(0,k-1):\n",
    "        cons = cons + ({'type': 'ineq', 'fun': lambda x: x[i]},)\n",
    "\n",
    "    bnds = ((0, None),)\n",
    "\n",
    "    for i in range(0,k-1):\n",
    "        bnds = bnds + ((0, None),)\n",
    "\n",
    "    return scipy.optimize.minimize(obj_fun, x_guess, method='SLSQP', jac=grad_obj_fun, bounds=bnds, constraints=cons, tol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialize data for testing; define matrix A along with strating guess\n",
    "\n",
    "N=10000 # number of SNPs\n",
    "j=15 # number of ancestries\n",
    "\n",
    "A=np.array(np.random.uniform(low=0, high=1, size=(N,1))) # initialize an array for experimental draws\n",
    "\n",
    "for i in range(1,j):\n",
    "    A=np.hstack((A,np.random.uniform(low=0, high=1, size=(N,1))))\n",
    "\n",
    "# First, we choose an answer! This vector must be Nx1\n",
    "\n",
    "ans=[[0.1], [0.1], [0.1], [0.25], [0.05], [0.1], [0.05], [0.05], [0.01], [0.01], [0.01], [0.01], [0.01], [0.05], [0.1]]\n",
    "\n",
    "mytaf=A@ans # Total allele frequency\n",
    "\n",
    "A=np.hstack((A,mytaf))\n",
    "\n",
    "x_t=(1/j)*np.ones((j,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fun: 6.263846093319523e-07\n",
      "     jac: array([ 0.01193129,  0.01929479,  0.03027043, -0.01620858,  0.07737389,\n",
      "       -0.00918604, -0.02817628,  0.01694641, -0.02168771, -0.04452949,\n",
      "       -0.03632284,  0.03320806, -0.04053936, -0.00658027, -0.00756653])\n",
      " message: 'Optimization terminated successfully.'\n",
      "    nfev: 63\n",
      "     nit: 28\n",
      "    njev: 28\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([0.10000438, 0.09999609, 0.09999595, 0.2500036 , 0.04998458,\n",
      "       0.10000132, 0.05000967, 0.04999994, 0.00998947, 0.01000382,\n",
      "       0.01000102, 0.00999105, 0.01000678, 0.05001041, 0.10000194])\n",
      "Time:  0.18364905328633085\n",
      "our correct answer was chosen to be [[0.1], [0.1], [0.1], [0.25], [0.05], [0.1], [0.05], [0.05], [0.01], [0.01], [0.01], [0.01], [0.01], [0.05], [0.1]]\n"
     ]
    }
   ],
   "source": [
    "### This cell runs and times the HA function\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "print(HA(A,x_t))\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('Time: ', stop - start)\n",
    "\n",
    "print('our correct answer was chosen to be', ans)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
