{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as scipy\n",
    "from scipy.optimize import minimize\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Solving Many Ancestries problem, multiple SNPs\n",
    "\n",
    "In this notebook we attempt to solve the following constrained, quadratic optimization problem:\n",
    "\n",
    "$$\\min_{\\pi \\in \\mathbb{R}^k} f(\\pi)=\\sum_{i=1}^{N}\\left(\\sum_{j=1}^k a_{j,i}\\pi_j-\\tilde{a}_i\\right)^2$$\n",
    "\n",
    "$$\\text{subject to:} \\sum_{j=1}^k \\pi_k=1 \\quad \\pi_j \\geq 0, j=1,\\ldots,k,$$\n",
    "\n",
    "where $a_{j,i} \\in \\mathbb{R}$, $j=1,\\ldots, k$; $i=1,\\ldots N$ and $\\tilde{a}_i \\in \\mathbb{R}$, $i =1, \\ldots, N$ are quantities obtained from a genetics simulation. The $a_{j,i}$'s correspond to the observed allele frequency in ancestry $j$ at SNP $i$. There are $k$ ancestries and $N$ SNPs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 15) (1000000, 1) (15, 1) (1000000, 1)\n"
     ]
    }
   ],
   "source": [
    "N=1000000 # number of SNPs\n",
    "k=15 # number of ancestries\n",
    "\n",
    "A=np.array(np.random.uniform(low=0, high=1, size=(N,1))) # initialize an array for experimental draws\n",
    "\n",
    "for i in range(1,k):\n",
    "    A=np.hstack((A,np.random.uniform(low=0, high=1, size=(N,1))))\n",
    "\n",
    "# First, we choose an answer! This vector must be Nx1\n",
    "\n",
    "ans=[[0.1], [0.1], [0.1], [0.25], [0.05], [0.1], [0.05], [0.05], [0.01], [0.01], [0.01], [0.01], [0.01], [0.05], [0.1]]\n",
    "\n",
    "taf=A@ans # Total allele frequency\n",
    "\n",
    "print(np.shape(A),np.shape(taf), np.shape(ans), np.shape(taf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the objective function!\n",
    "\n",
    "def gen_function(x):\n",
    "    b=0\n",
    "    for i in range(0,k):\n",
    "        b=b + x[i]*A[:,i:(i+1)]\n",
    "    b=b-taf\n",
    "    return np.sum(b**2, axis=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check shape of x_t: (15, 1) [1.]\n",
      "our initial value is [[0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      "  0.06666667 0.06666667 0.06666667 0.06666667 0.06666667 0.06666667\n",
      "  0.06666667 0.06666667 0.06666667]]\n",
      "which has function value 4704.590148775938\n"
     ]
    }
   ],
   "source": [
    "# This is a feasible initial point since its components add to 1 and are positive.\n",
    "\n",
    "x_t=(1/k)*np.ones((k,1))\n",
    "print('check shape of x_t:', np.shape(x_t), np.sum(x_t,axis=0))\n",
    "\n",
    "# Make sure function works by computing f(x_t)\n",
    "\n",
    "print('our initial value is', np.transpose(x_t)) # transpose for readability only\n",
    "print('which has function value', gen_function(x_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the gradient of the objective function\n",
    "\n",
    "def gen_gradfun(x):\n",
    "    \n",
    "    gradvec = np.zeros((k,1))\n",
    "    \n",
    "    d=0\n",
    "    \n",
    "    for i in range(0,k):\n",
    "        d=d + x[i]*A[:,i:(i+1)]\n",
    "    d=d-taf\n",
    "    \n",
    "    for i in range(0,k):\n",
    "        gradvec[i,:] = np.sum(2*A[:,i:(i+1)]*d, axis=0)\n",
    "    return gradvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad of starting point is: [[ -5553.87228219  -5569.94891954  -5548.51811088 -30615.9706914\n",
      "    2772.9344849   -5475.50047128   2817.07523245   2799.14522459\n",
      "    9472.93969656   9541.15054213   9485.9454706    9441.10765977\n",
      "    9456.53309987   2828.42229237  -5554.89172561]]\n",
      "should be zeros: [[-2.02678189e-12 -1.81913868e-12 -1.93921923e-12 -2.57952893e-12\n",
      "  -1.90159013e-12 -1.65816568e-12 -1.89724446e-12 -1.93425240e-12\n",
      "  -1.87783881e-12 -1.80711866e-12 -1.97046979e-12 -1.87444958e-12\n",
      "  -1.85696081e-12 -1.66810283e-12 -1.63727646e-12]]\n"
     ]
    }
   ],
   "source": [
    "s=gen_gradfun(x_t)\n",
    "zero=gen_gradfun(ans)\n",
    "\n",
    "print('grad of starting point is:',np.transpose(s)) # this is the gradient of where we begin\n",
    "print('should be zeros:',np.transpose(zero)) # this should be zero if we have the right answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SLSQP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are wrappers that make our constraints and our bounds\n",
    "\n",
    "cons = ({'type': 'eq', 'fun': lambda x:  np.sum(x,axis=0) -1},)\n",
    "\n",
    "for i in range(0,k-1):\n",
    "    cons = cons + ({'type': 'ineq', 'fun': lambda x: x[i]},)\n",
    "\n",
    "bnds = ((0, None),)\n",
    "\n",
    "for i in range(0,k-1):\n",
    "    bnds = bnds + ((0, None),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fun: 2.3303816374487528e-07\n",
      "     jac: array([-0.06178706,  0.02979919,  0.09644771, -0.05492109, -0.11486172,\n",
      "       -0.04203461, -0.05020217, -0.02116906,  0.1599231 , -0.00062829,\n",
      "        0.02027204,  0.09433528, -0.05170179, -0.05372333,  0.04808821])\n",
      " message: 'Optimization terminated successfully.'\n",
      "    nfev: 91\n",
      "     nit: 37\n",
      "    njev: 37\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([0.09999963, 0.10000018, 0.10000058, 0.24999967, 0.04999931,\n",
      "       0.09999975, 0.0499997 , 0.04999987, 0.01000096, 0.01      ,\n",
      "       0.01000012, 0.01000057, 0.00999969, 0.04999968, 0.10000029])\n",
      "Time:  64.7779243949326\n",
      "our correct answer was chosen to be [[0.1], [0.1], [0.1], [0.25], [0.05], [0.1], [0.05], [0.05], [0.01], [0.01], [0.01], [0.01], [0.01], [0.05], [0.1]]\n"
     ]
    }
   ],
   "source": [
    "# This cell runs and times SLSQP\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "print(scipy.optimize.minimize(gen_function, x_t, method='SLSQP', jac=gen_gradfun, bounds=bnds, constraints=cons, tol=1e-5))\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('Time: ', stop - start)\n",
    "\n",
    "print('our correct answer was chosen to be', ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do we call the computed answer, x, without copy/pasting?!\n",
    "\n",
    "x=np.array([0.09999963, 0.10000018, 0.10000058, 0.24999967, 0.04999931,\n",
    "       0.09999975, 0.0499997 , 0.04999987, 0.01000096, 0.01      ,\n",
    "       0.01000012, 0.01000057, 0.00999969, 0.04999968, 0.10000029])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.59999999999503e-07"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out the error in the worst component\n",
    "\n",
    "np.max(abs(x-np.transpose(ans)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4666666666635825e-08"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out average error\n",
    "\n",
    "(1/k)*np.sum(abs(x-np.transpose(ans)),axis=0)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
